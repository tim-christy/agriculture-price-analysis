{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "I have to deduplicate and clean the data before I can adjust all prices for inflation. Since there are 22 different produce items, this will take some work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import os\n",
    "import sys\n",
    "src_dir = '../../src/d01_data/'\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "import d01_data as data_functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '../../data/00_raw/agriculture_prices.db'\n",
    "df = data_functions.download_data_from_db(path_to_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data and Adding Features\n",
    "Updating all prices to reflect 2019 dollars (adjust for inflation), and will be taking an average for all retail prices. \n",
    "\n",
    "Since this needs to be done by commodity, I am also going to make a dictionary that holds data frames by commodity, produce_dict. So for example, typing ``produce_dict['Strawberries']`` will return a dataframe concerning only strawberries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below makes the dictionary discussed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_dict = data_functions.make_dictionary_of_dataframes(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalizing Data Cleaning for all Dataframes\n",
    "\n",
    "I am going to write functions that will automate all the data clean up for each of the 22 dataframes. Starting with the NaN values. \n",
    "\n",
    "First, let's observe the total number of NaN values for each dataframe. I also know, from working with the Strawberries df in the lab book, that there are zeros in there where there shouldn't be. I'm going to convert those (or anything less than that) to NaN and count those in the total. So long as the NaN count does not exceed 10% of the data frame, I'll likely drop it. But first, will need to get a count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_na(df):\n",
    "    '''\n",
    "    Description: Counts the number of NaN values in a data frame\n",
    "    Parameters: df - The dataframe to be checked\n",
    "    Returns: None. Prints our the percentage of each column that is nan\n",
    "    '''\n",
    "    # Anywhere a price is equal to or less than zero, assign it to NaN\n",
    "    df[df.loc[:, ['Farm Price', 'Atlanta Retail', 'Chicago Retail', 'Los Angeles Retail', 'NYC Retail']] <= 0] = np.nan\n",
    "    print(f'Percentage NaN for {df.iloc[0, -1]}: \\n {round((df.isna().sum())/len(df), 3)*100}')\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage NaN for Strawberries: \n",
      " Farm Price            0.0\n",
      "Atlanta Retail        0.0\n",
      "Chicago Retail        6.9\n",
      "Los Angeles Retail    0.3\n",
      "NYC Retail            0.3\n",
      "Avg Spread            0.0\n",
      "Commodity             0.0\n",
      "dtype: float64\n",
      " \n",
      "Percentage NaN for Romaine Lettuce: \n",
      " Farm Price            0.0\n",
      "Atlanta Retail        0.0\n",
      "Chicago Retail        5.7\n",
      "Los Angeles Retail    0.2\n",
      "NYC Retail            0.4\n",
      "Avg Spread            0.0\n",
      "Commodity             0.0\n",
      "dtype: float64\n",
      " \n",
      "Percentage NaN for Red Leaf Lettuce: \n",
      " Farm Price            0.0\n",
      "Atlanta Retail        0.0\n",
      "Chicago Retail        5.1\n",
      "Los Angeles Retail    0.2\n",
      "NYC Retail            0.4\n",
      "Avg Spread            0.0\n",
      "Commodity             0.0\n",
      "dtype: float64\n",
      " \n",
      "Percentage NaN for Potatoes: \n",
      " Farm Price            0.1\n",
      "Atlanta Retail        0.1\n",
      "Chicago Retail        6.1\n",
      "Los Angeles Retail    0.1\n",
      "NYC Retail            4.8\n",
      "Avg Spread            0.0\n",
      "Commodity             0.0\n",
      "dtype: float64\n",
      " \n",
      "Percentage NaN for Oranges: \n",
      " Farm Price            0.1\n",
      "Atlanta Retail        1.4\n",
      "Chicago Retail        6.7\n",
      "Los Angeles Retail    0.4\n",
      "NYC Retail            4.2\n",
      "Avg Spread            0.0\n",
      "Commodity             0.0\n",
      "dtype: float64\n",
      " \n",
      "Percentage NaN for Iceberg Lettuce: \n",
      " Farm Price            0.1\n",
      "Atlanta Retail        1.1\n",
      "Chicago Retail        6.2\n",
      "Los Angeles Retail    0.3\n",
      "NYC Retail            3.5\n",
      "Avg Spread            0.0\n",
      "Commodity             0.0\n",
      "dtype: float64\n",
      " \n",
      "Percentage NaN for Green Leaf Lettuce: \n",
      " Farm Price            0.1\n",
      "Atlanta Retail        1.0\n",
      "Chicago Retail        5.8\n",
      "Los Angeles Retail    0.3\n",
      "NYC Retail            3.0\n",
      "Avg Spread            0.0\n",
      "Commodity             0.0\n",
      "dtype: float64\n",
      " \n",
      "Percentage NaN for Celery: \n",
      " Farm Price            0.1\n",
      "Atlanta Retail        0.9\n",
      "Chicago Retail        5.6\n",
      "Los Angeles Retail    0.3\n",
      "NYC Retail            2.7\n",
      "Avg Spread            0.0\n",
      "Commodity             0.0\n",
      "dtype: float64\n",
      " \n",
      "Percentage NaN for Cauliflower: \n",
      " Farm Price            0.1\n",
      "Atlanta Retail        0.8\n",
      "Chicago Retail        5.4\n",
      "Los Angeles Retail    0.3\n",
      "NYC Retail            2.4\n",
      "Avg Spread            0.0\n",
      "Commodity             0.0\n",
      "dtype: float64\n",
      " \n",
      "Percentage NaN for Carrots: \n",
      " Farm Price            0.1\n",
      "Atlanta Retail        0.7\n",
      "Chicago Retail        5.3\n",
      "Los Angeles Retail    0.3\n",
      "NYC Retail            2.2\n",
      "Avg Spread            0.0\n",
      "Commodity             0.0\n",
      "dtype: float64\n",
      " \n",
      "Percentage NaN for Cantaloupe: \n",
      " Farm Price            0.0\n",
      "Atlanta Retail        0.6\n",
      "Chicago Retail        5.4\n",
      "Los Angeles Retail    0.3\n",
      "NYC Retail            2.1\n",
      "Avg Spread            0.0\n",
      "Commodity             0.0\n",
      "dtype: float64\n",
      " \n",
      "Percentage NaN for Broccoli Crowns: \n",
      " Farm Price            0.0\n",
      "Atlanta Retail        0.6\n",
      "Chicago Retail        5.3\n",
      "Los Angeles Retail    0.3\n",
      "NYC Retail            1.9\n",
      "Avg Spread            0.0\n",
      "Commodity             0.0\n",
      "dtype: float64\n",
      " \n",
      "Percentage NaN for Avocados: \n",
      " Farm Price            0.0\n",
      "Atlanta Retail        0.6\n",
      "Chicago Retail        5.5\n",
      "Los Angeles Retail    0.3\n",
      "NYC Retail            1.8\n",
      "Avg Spread            0.0\n",
      "Commodity             0.0\n",
      "dtype: float64\n",
      " \n",
      "Percentage NaN for Broccoli Bunches: \n",
      " Farm Price            0.0\n",
      "Atlanta Retail        0.5\n",
      "Chicago Retail        5.7\n",
      "Los Angeles Retail    0.3\n",
      "NYC Retail            1.7\n",
      "Avg Spread            0.0\n",
      "Commodity             0.0\n",
      "dtype: float64\n",
      " \n",
      "Percentage NaN for Asparagus: \n",
      " Farm Price            0.0\n",
      "Atlanta Retail        0.5\n",
      "Chicago Retail        5.8\n",
      "Los Angeles Retail    0.3\n",
      "NYC Retail            1.7\n",
      "Avg Spread            0.0\n",
      "Commodity             0.0\n",
      "dtype: float64\n",
      " \n",
      "Percentage NaN for Flame Grapes: \n",
      " Farm Price            0.0\n",
      "Atlanta Retail        0.5\n",
      "Chicago Retail        5.8\n",
      "Los Angeles Retail    0.3\n",
      "NYC Retail            1.7\n",
      "Avg Spread            0.0\n",
      "Commodity             0.0\n",
      "dtype: float64\n",
      " \n",
      "Percentage NaN for Thompson Grapes: \n",
      " Farm Price            0.1\n",
      "Atlanta Retail        0.5\n",
      "Chicago Retail        5.8\n",
      "Los Angeles Retail    0.3\n",
      "NYC Retail            1.7\n",
      "Avg Spread            0.0\n",
      "Commodity             0.0\n",
      "dtype: float64\n",
      " \n",
      "Percentage NaN for Honeydews: \n",
      " Farm Price            0.0\n",
      "Atlanta Retail        0.5\n",
      "Chicago Retail        5.9\n",
      "Los Angeles Retail    0.3\n",
      "NYC Retail            1.7\n",
      "Avg Spread            0.0\n",
      "Commodity             0.0\n",
      "dtype: float64\n",
      " \n",
      "Percentage NaN for Tomatoes: \n",
      " Farm Price            0.1\n",
      "Atlanta Retail        0.5\n",
      "Chicago Retail        6.3\n",
      "Los Angeles Retail    0.5\n",
      "NYC Retail            1.8\n",
      "Avg Spread            0.0\n",
      "Commodity             0.0\n",
      "dtype: float64\n",
      " \n",
      "Percentage NaN for Plums: \n",
      " Farm Price            0.1\n",
      "Atlanta Retail        0.6\n",
      "Chicago Retail        6.3\n",
      "Los Angeles Retail    0.5\n",
      "NYC Retail            1.9\n",
      "Avg Spread            0.0\n",
      "Commodity             0.0\n",
      "dtype: float64\n",
      " \n",
      "Percentage NaN for Peaches: \n",
      " Farm Price            0.1\n",
      "Atlanta Retail        0.9\n",
      "Chicago Retail        6.3\n",
      "Los Angeles Retail    0.5\n",
      "NYC Retail            2.1\n",
      "Avg Spread            0.0\n",
      "Commodity             0.0\n",
      "dtype: float64\n",
      " \n",
      "Percentage NaN for Nectarines: \n",
      " Farm Price            0.1\n",
      "Atlanta Retail        1.2\n",
      "Chicago Retail        6.3\n",
      "Los Angeles Retail    0.5\n",
      "NYC Retail            2.2\n",
      "Avg Spread            0.0\n",
      "Commodity             0.0\n",
      "dtype: float64\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for produce in list(produce_dict.keys()):\n",
    "    count_na(produce_dict[produce])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaN Values are good to drop. They comprise less than 10% of each column.\n",
    "\n",
    "Why not just drop all NaN values? The reason I chose to use this criteria is that the more data you have, the better the models you can make with the data. Often one column might be missing many data points but the other columns have those data points present. For example, in the Nectarines dataframe above, only 0.1% of the Farm Price data is NaN while 6.3% of the Chicago Retail data is NaN. When I drop all NaN values, any row with an NaN value is going to be dropped. This means that I will lose 6.3% of my data in the Farm Price column despite only actually missing 0.1%. Same goes for all columns.  \n",
    "\n",
    "In short, you want to keep as much data as you can because the quality of the models you build are dependent on it. If you use drop_na() on your data, you will drop all rows with any missing values, even if it is only because one column was NaN. So you will be throwing away the same percentage of data as your worst column. For example, I will be throwing away 6.3% of all my Nectarines data even though the other columns are missing much less than that.  \n",
    "\n",
    "A common strategy for salvaging some of this data is in replacing the missing values with the median value or values you know to make sense for the data. But if you don't need to do it, it's much faster to just drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_all_na(df):\n",
    "    '''\n",
    "    Description: Drops all rows in a dataframe that have values of NaN\n",
    "    Parameters: df - the dataframe to have NaN values dropped\n",
    "    Returns: the dataframe with all NaN values taken out\n",
    "    '''\n",
    "    \n",
    "    df_return = df.dropna(inplace=True)\n",
    "    return df_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for produce in list(produce_dict.keys()):\n",
    "    produce_dict.setdefault(produce, drop_all_na(produce_dict[produce]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Farm Price            0\n",
       "Atlanta Retail        0\n",
       "Chicago Retail        0\n",
       "Los Angeles Retail    0\n",
       "NYC Retail            0\n",
       "Avg Spread            0\n",
       "Commodity             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "produce_dict['Nectarines'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deduplicating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "12\n",
      "23\n",
      "45\n",
      "52\n",
      "60\n",
      "132\n",
      "139\n",
      "145\n",
      "312\n",
      "315\n",
      "321\n",
      "328\n",
      "332\n",
      "336\n",
      "339\n",
      "342\n",
      "344\n",
      "346\n",
      "350\n",
      "352\n",
      "355\n"
     ]
    }
   ],
   "source": [
    "for produce in list(produce_dict.keys()):\n",
    "    print(produce_dict[produce].duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future note to self:   \n",
    "\n",
    "Wait until you have a total count of NaN values and duplicated values to get a better idea of the amount of data you are going to lose. It's a small enough quantity here to not worry about it, but that might not always be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_all_dupes(df):\n",
    "    '''\n",
    "    Description: Drops all duplicates in a dataframe\n",
    "    Parameters: dataframe to drop all duplicates\n",
    "    returns: deduplicated dataframe\n",
    "    '''\n",
    "    df_return = df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    return df_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for produce in list(produce_dict.keys()):\n",
    "    produce_dict.setdefault(produce, drop_all_dupes(produce_dict[produce]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "produce_dict['Nectarines'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "produce_dict['Strawberries'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 907 entries, 2019-05-19 to 2001-02-04\n",
      "Data columns (total 7 columns):\n",
      "Farm Price            907 non-null float64\n",
      "Atlanta Retail        907 non-null float64\n",
      "Chicago Retail        907 non-null float64\n",
      "Los Angeles Retail    907 non-null float64\n",
      "NYC Retail            907 non-null float64\n",
      "Avg Spread            907 non-null object\n",
      "Commodity             907 non-null object\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 56.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1840 entries, 2019-05-19 to 2001-02-04\n",
      "Data columns (total 7 columns):\n",
      "Farm Price            1840 non-null float64\n",
      "Atlanta Retail        1840 non-null float64\n",
      "Chicago Retail        1840 non-null float64\n",
      "Los Angeles Retail    1840 non-null float64\n",
      "NYC Retail            1840 non-null float64\n",
      "Avg Spread            1840 non-null object\n",
      "Commodity             1840 non-null object\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 115.0+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2772 entries, 2019-05-19 to 2001-02-04\n",
      "Data columns (total 7 columns):\n",
      "Farm Price            2772 non-null float64\n",
      "Atlanta Retail        2772 non-null float64\n",
      "Chicago Retail        2772 non-null float64\n",
      "Los Angeles Retail    2772 non-null float64\n",
      "NYC Retail            2772 non-null float64\n",
      "Avg Spread            2772 non-null object\n",
      "Commodity             2772 non-null object\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 173.2+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3361 entries, 2019-05-19 to 2001-02-04\n",
      "Data columns (total 7 columns):\n",
      "Farm Price            3361 non-null float64\n",
      "Atlanta Retail        3361 non-null float64\n",
      "Chicago Retail        3361 non-null float64\n",
      "Los Angeles Retail    3361 non-null float64\n",
      "NYC Retail            3361 non-null float64\n",
      "Avg Spread            3361 non-null object\n",
      "Commodity             3361 non-null object\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 210.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 4077 entries, 2019-05-19 to 2001-06-03\n",
      "Data columns (total 7 columns):\n",
      "Farm Price            4077 non-null float64\n",
      "Atlanta Retail        4077 non-null float64\n",
      "Chicago Retail        4077 non-null float64\n",
      "Los Angeles Retail    4077 non-null float64\n",
      "NYC Retail            4077 non-null float64\n",
      "Avg Spread            4077 non-null object\n",
      "Commodity             4077 non-null object\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 254.8+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 5016 entries, 2019-05-19 to 2001-02-04\n",
      "Data columns (total 7 columns):\n",
      "Farm Price            5016 non-null float64\n",
      "Atlanta Retail        5016 non-null float64\n",
      "Chicago Retail        5016 non-null float64\n",
      "Los Angeles Retail    5016 non-null float64\n",
      "NYC Retail            5016 non-null float64\n",
      "Avg Spread            5016 non-null object\n",
      "Commodity             5016 non-null object\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 313.5+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 5888 entries, 2019-05-19 to 2001-02-04\n",
      "Data columns (total 7 columns):\n",
      "Farm Price            5888 non-null float64\n",
      "Atlanta Retail        5888 non-null float64\n",
      "Chicago Retail        5888 non-null float64\n",
      "Los Angeles Retail    5888 non-null float64\n",
      "NYC Retail            5888 non-null float64\n",
      "Avg Spread            5888 non-null object\n",
      "Commodity             5888 non-null object\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 368.0+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 6824 entries, 2019-05-19 to 2001-02-04\n",
      "Data columns (total 7 columns):\n",
      "Farm Price            6824 non-null float64\n",
      "Atlanta Retail        6824 non-null float64\n",
      "Chicago Retail        6824 non-null float64\n",
      "Los Angeles Retail    6824 non-null float64\n",
      "NYC Retail            6824 non-null float64\n",
      "Avg Spread            6824 non-null object\n",
      "Commodity             6824 non-null object\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 426.5+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 7765 entries, 2019-05-19 to 2001-02-04\n",
      "Data columns (total 7 columns):\n",
      "Farm Price            7765 non-null float64\n",
      "Atlanta Retail        7765 non-null float64\n",
      "Chicago Retail        7765 non-null float64\n",
      "Los Angeles Retail    7765 non-null float64\n",
      "NYC Retail            7765 non-null float64\n",
      "Avg Spread            7765 non-null object\n",
      "Commodity             7765 non-null object\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 485.3+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 8536 entries, 2019-05-19 to 2001-02-04\n",
      "Data columns (total 7 columns):\n",
      "Farm Price            8536 non-null float64\n",
      "Atlanta Retail        8536 non-null float64\n",
      "Chicago Retail        8536 non-null float64\n",
      "Los Angeles Retail    8536 non-null float64\n",
      "NYC Retail            8536 non-null float64\n",
      "Avg Spread            8536 non-null object\n",
      "Commodity             8536 non-null object\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 533.5+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 8997 entries, 2019-05-19 to 2001-06-03\n",
      "Data columns (total 7 columns):\n",
      "Farm Price            8997 non-null float64\n",
      "Atlanta Retail        8997 non-null float64\n",
      "Chicago Retail        8997 non-null float64\n",
      "Los Angeles Retail    8997 non-null float64\n",
      "NYC Retail            8997 non-null float64\n",
      "Avg Spread            8997 non-null object\n",
      "Commodity             8997 non-null object\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 562.3+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 9928 entries, 2019-05-19 to 2001-02-04\n",
      "Data columns (total 7 columns):\n",
      "Farm Price            9928 non-null float64\n",
      "Atlanta Retail        9928 non-null float64\n",
      "Chicago Retail        9928 non-null float64\n",
      "Los Angeles Retail    9928 non-null float64\n",
      "NYC Retail            9928 non-null float64\n",
      "Avg Spread            9928 non-null object\n",
      "Commodity             9928 non-null object\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 620.5+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 10573 entries, 2019-05-19 to 2001-02-04\n",
      "Data columns (total 7 columns):\n",
      "Farm Price            10573 non-null float64\n",
      "Atlanta Retail        10573 non-null float64\n",
      "Chicago Retail        10573 non-null float64\n",
      "Los Angeles Retail    10573 non-null float64\n",
      "NYC Retail            10573 non-null float64\n",
      "Avg Spread            10573 non-null object\n",
      "Commodity             10573 non-null object\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 660.8+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 11467 entries, 2019-05-19 to 2001-02-04\n",
      "Data columns (total 7 columns):\n",
      "Farm Price            11467 non-null float64\n",
      "Atlanta Retail        11467 non-null float64\n",
      "Chicago Retail        11467 non-null float64\n",
      "Los Angeles Retail    11467 non-null float64\n",
      "NYC Retail            11467 non-null float64\n",
      "Avg Spread            11467 non-null object\n",
      "Commodity             11467 non-null object\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 716.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 11698 entries, 2019-05-19 to 2001-04-01\n",
      "Data columns (total 7 columns):\n",
      "Farm Price            11698 non-null float64\n",
      "Atlanta Retail        11698 non-null float64\n",
      "Chicago Retail        11698 non-null float64\n",
      "Los Angeles Retail    11698 non-null float64\n",
      "NYC Retail            11698 non-null float64\n",
      "Avg Spread            11698 non-null object\n",
      "Commodity             11698 non-null object\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 731.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 12167 entries, 2019-05-19 to 2001-06-03\n",
      "Data columns (total 7 columns):\n",
      "Farm Price            12167 non-null float64\n",
      "Atlanta Retail        12167 non-null float64\n",
      "Chicago Retail        12167 non-null float64\n",
      "Los Angeles Retail    12167 non-null float64\n",
      "NYC Retail            12167 non-null float64\n",
      "Avg Spread            12167 non-null object\n",
      "Commodity             12167 non-null object\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 760.4+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 12426 entries, 2019-05-19 to 2002-09-15\n",
      "Data columns (total 7 columns):\n",
      "Farm Price            12426 non-null float64\n",
      "Atlanta Retail        12426 non-null float64\n",
      "Chicago Retail        12426 non-null float64\n",
      "Los Angeles Retail    12426 non-null float64\n",
      "NYC Retail            12426 non-null float64\n",
      "Avg Spread            12426 non-null object\n",
      "Commodity             12426 non-null object\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 776.6+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 12850 entries, 2019-05-19 to 2001-11-04\n",
      "Data columns (total 7 columns):\n",
      "Farm Price            12850 non-null float64\n",
      "Atlanta Retail        12850 non-null float64\n",
      "Chicago Retail        12850 non-null float64\n",
      "Los Angeles Retail    12850 non-null float64\n",
      "NYC Retail            12850 non-null float64\n",
      "Avg Spread            12850 non-null object\n",
      "Commodity             12850 non-null object\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 803.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 13181 entries, 2019-05-19 to 2001-02-04\n",
      "Data columns (total 7 columns):\n",
      "Farm Price            13181 non-null float64\n",
      "Atlanta Retail        13181 non-null float64\n",
      "Chicago Retail        13181 non-null float64\n",
      "Los Angeles Retail    13181 non-null float64\n",
      "NYC Retail            13181 non-null float64\n",
      "Avg Spread            13181 non-null object\n",
      "Commodity             13181 non-null object\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 823.8+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 13371 entries, 2019-05-19 to 2001-07-15\n",
      "Data columns (total 7 columns):\n",
      "Farm Price            13371 non-null float64\n",
      "Atlanta Retail        13371 non-null float64\n",
      "Chicago Retail        13371 non-null float64\n",
      "Los Angeles Retail    13371 non-null float64\n",
      "NYC Retail            13371 non-null float64\n",
      "Avg Spread            13371 non-null object\n",
      "Commodity             13371 non-null object\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 835.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 13595 entries, 2019-05-19 to 2001-06-03\n",
      "Data columns (total 7 columns):\n",
      "Farm Price            13595 non-null float64\n",
      "Atlanta Retail        13595 non-null float64\n",
      "Chicago Retail        13595 non-null float64\n",
      "Los Angeles Retail    13595 non-null float64\n",
      "NYC Retail            13595 non-null float64\n",
      "Avg Spread            13595 non-null object\n",
      "Commodity             13595 non-null object\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 849.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 13821 entries, 2019-05-19 to 2001-06-03\n",
      "Data columns (total 7 columns):\n",
      "Farm Price            13821 non-null float64\n",
      "Atlanta Retail        13821 non-null float64\n",
      "Chicago Retail        13821 non-null float64\n",
      "Los Angeles Retail    13821 non-null float64\n",
      "NYC Retail            13821 non-null float64\n",
      "Avg Spread            13821 non-null object\n",
      "Commodity             13821 non-null object\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 863.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for produce in list(produce_dict.keys()):\n",
    "    print(produce_dict[produce].info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes are clean. Time to convert prices to 2019 USD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusting prices for inflation based on month using the consumer price index data found here [https://www.usinflationcalculator.com/inflation/consumer-price-index-and-annual-percent-changes-from-1913-to-2008/](https://www.usinflationcalculator.com/inflation/consumer-price-index-and-annual-percent-changes-from-1913-to-2008/)\n",
    "\n",
    "Everything will be changed to correspond to USD in November of 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi_df = pd.read_csv('../../data/00_raw/cpi.csv', index_col=0, header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jan</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "      <th>Apr</th>\n",
       "      <th>May</th>\n",
       "      <th>June</th>\n",
       "      <th>July</th>\n",
       "      <th>Aug</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Dec</th>\n",
       "      <th>Avg</th>\n",
       "      <th>Dec-Dec</th>\n",
       "      <th>Avg-Avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>9.800</td>\n",
       "      <td>9.800</td>\n",
       "      <td>9.800</td>\n",
       "      <td>9.800</td>\n",
       "      <td>9.700</td>\n",
       "      <td>9.800</td>\n",
       "      <td>9.900</td>\n",
       "      <td>9.900</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.100</td>\n",
       "      <td>10.000</td>\n",
       "      <td>9.900</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>10.000</td>\n",
       "      <td>9.900</td>\n",
       "      <td>9.900</td>\n",
       "      <td>9.800</td>\n",
       "      <td>9.900</td>\n",
       "      <td>9.900</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.200</td>\n",
       "      <td>10.200</td>\n",
       "      <td>10.100</td>\n",
       "      <td>10.200</td>\n",
       "      <td>10.100</td>\n",
       "      <td>10.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>10.100</td>\n",
       "      <td>10.000</td>\n",
       "      <td>9.900</td>\n",
       "      <td>10.000</td>\n",
       "      <td>10.100</td>\n",
       "      <td>10.100</td>\n",
       "      <td>10.100</td>\n",
       "      <td>10.100</td>\n",
       "      <td>10.100</td>\n",
       "      <td>10.200</td>\n",
       "      <td>10.300</td>\n",
       "      <td>10.300</td>\n",
       "      <td>10.100</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>10.400</td>\n",
       "      <td>10.400</td>\n",
       "      <td>10.500</td>\n",
       "      <td>10.600</td>\n",
       "      <td>10.700</td>\n",
       "      <td>10.800</td>\n",
       "      <td>10.800</td>\n",
       "      <td>10.900</td>\n",
       "      <td>11.100</td>\n",
       "      <td>11.300</td>\n",
       "      <td>11.500</td>\n",
       "      <td>11.600</td>\n",
       "      <td>10.900</td>\n",
       "      <td>12.6</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>11.700</td>\n",
       "      <td>12.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>12.600</td>\n",
       "      <td>12.800</td>\n",
       "      <td>13.000</td>\n",
       "      <td>12.800</td>\n",
       "      <td>13.000</td>\n",
       "      <td>13.300</td>\n",
       "      <td>13.500</td>\n",
       "      <td>13.500</td>\n",
       "      <td>13.700</td>\n",
       "      <td>12.800</td>\n",
       "      <td>18.1</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>233.707</td>\n",
       "      <td>234.722</td>\n",
       "      <td>236.119</td>\n",
       "      <td>236.599</td>\n",
       "      <td>237.805</td>\n",
       "      <td>238.638</td>\n",
       "      <td>238.654</td>\n",
       "      <td>238.316</td>\n",
       "      <td>237.945</td>\n",
       "      <td>237.838</td>\n",
       "      <td>237.336</td>\n",
       "      <td>236.525</td>\n",
       "      <td>237.017</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>236.916</td>\n",
       "      <td>237.111</td>\n",
       "      <td>238.132</td>\n",
       "      <td>239.261</td>\n",
       "      <td>240.236</td>\n",
       "      <td>241.038</td>\n",
       "      <td>240.647</td>\n",
       "      <td>240.853</td>\n",
       "      <td>241.428</td>\n",
       "      <td>241.729</td>\n",
       "      <td>241.353</td>\n",
       "      <td>241.432</td>\n",
       "      <td>240.007</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>242.839</td>\n",
       "      <td>243.603</td>\n",
       "      <td>243.801</td>\n",
       "      <td>244.524</td>\n",
       "      <td>244.733</td>\n",
       "      <td>244.955</td>\n",
       "      <td>244.786</td>\n",
       "      <td>245.519</td>\n",
       "      <td>246.819</td>\n",
       "      <td>246.663</td>\n",
       "      <td>246.669</td>\n",
       "      <td>246.524</td>\n",
       "      <td>245.120</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>247.867</td>\n",
       "      <td>248.991</td>\n",
       "      <td>249.554</td>\n",
       "      <td>250.546</td>\n",
       "      <td>251.588</td>\n",
       "      <td>251.989</td>\n",
       "      <td>252.006</td>\n",
       "      <td>252.146</td>\n",
       "      <td>252.439</td>\n",
       "      <td>252.885</td>\n",
       "      <td>252.038</td>\n",
       "      <td>251.233</td>\n",
       "      <td>251.107</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>251.712</td>\n",
       "      <td>252.776</td>\n",
       "      <td>254.202</td>\n",
       "      <td>255.548</td>\n",
       "      <td>256.092</td>\n",
       "      <td>256.143</td>\n",
       "      <td>256.571</td>\n",
       "      <td>256.558</td>\n",
       "      <td>256.759</td>\n",
       "      <td>257.346</td>\n",
       "      <td>257.208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Jan      Feb      Mar      Apr      May     June     July      Aug  \\\n",
       "Year                                                                           \n",
       "1913    9.800    9.800    9.800    9.800    9.700    9.800    9.900    9.900   \n",
       "1914   10.000    9.900    9.900    9.800    9.900    9.900   10.000   10.200   \n",
       "1915   10.100   10.000    9.900   10.000   10.100   10.100   10.100   10.100   \n",
       "1916   10.400   10.400   10.500   10.600   10.700   10.800   10.800   10.900   \n",
       "1917   11.700   12.000   12.000   12.600   12.800   13.000   12.800   13.000   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "2015  233.707  234.722  236.119  236.599  237.805  238.638  238.654  238.316   \n",
       "2016  236.916  237.111  238.132  239.261  240.236  241.038  240.647  240.853   \n",
       "2017  242.839  243.603  243.801  244.524  244.733  244.955  244.786  245.519   \n",
       "2018  247.867  248.991  249.554  250.546  251.588  251.989  252.006  252.146   \n",
       "2019  251.712  252.776  254.202  255.548  256.092  256.143  256.571  256.558   \n",
       "\n",
       "          Sep      Oct      Nov      Dec      Avg Dec-Dec Avg-Avg  \n",
       "Year                                                               \n",
       "1913   10.000   10.000   10.100   10.000    9.900       –       –  \n",
       "1914   10.200   10.100   10.200   10.100   10.000       1       1  \n",
       "1915   10.100   10.200   10.300   10.300   10.100       2       1  \n",
       "1916   11.100   11.300   11.500   11.600   10.900    12.6     7.9  \n",
       "1917   13.300   13.500   13.500   13.700   12.800    18.1    17.4  \n",
       "...       ...      ...      ...      ...      ...     ...     ...  \n",
       "2015  237.945  237.838  237.336  236.525  237.017     0.7     0.1  \n",
       "2016  241.428  241.729  241.353  241.432  240.007     2.1     1.3  \n",
       "2017  246.819  246.663  246.669  246.524  245.120     2.1     2.1  \n",
       "2018  252.439  252.885  252.038  251.233  251.107     1.9     2.4  \n",
       "2019  256.759  257.346  257.208      NaN      NaN     NaN     NaN  \n",
       "\n",
       "[107 rows x 15 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion to 2019 dollars and making an average retail column\n",
    "\n",
    "The objective is to translate all prices in the dataframes to 2019 dollars of the most recent cpi. I have to match the month and year from the index of the produce data frames to the month and year from the cpi data frame and multiply by todays cpi divided by the cpi during that month and year.\n",
    "\n",
    "First method I can immediately think of is to loop through each dataframe and apply the conversion where the months and year match. This isn't so bad on this dataframe but for large data it would be inefficient. In that case I would start thinking about how you could use arrays to process the data.  \n",
    "\n",
    "It would be nice to see the average retail prices of the five cities listed so the following function also appends and average city retail price and the variance of that average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi_cols = ['1', '2', '3' , '4', '5', '6', '7', '8', '9', '10', '11', '12', 'Avg', 'Dec-Dec', 'Avg-Avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi_df.columns = cpi_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPI_2019 = cpi_df.loc[2019][10] # Data frame is zero indexed... 0 is Jan and 1 is Feb etc for second argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257.20799999999997"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CPI_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inflation_adjustment_for_df(df):\n",
    "    '''\n",
    "    Description: Adjusts all individual prices in a dataframe to December 2019. That is, it adjusts for inflation and \n",
    "                 reflects the value of a dollar in December 2019. Also creates an average retail column with stdev\n",
    "    Parameter: Dataframe to be adjusted\n",
    "    Returns: Inflation adjusted dataframe and an appended average column and stdev column\n",
    "    '''\n",
    "    farm = []\n",
    "    atl = []\n",
    "    chi=[]\n",
    "    la=[]\n",
    "    nyc =[]\n",
    "\n",
    "    for index_row in df.index:\n",
    "        count = 0\n",
    "        for column in df.columns:\n",
    "            conversion = (CPI_2019/cpi_df.loc[index_row.year][index_row.month - 1])\n",
    "            value = df[str(index_row)][str(column)].values[0]*conversion\n",
    "            if column == 'Farm Price':\n",
    "                farm.append(round(value, 2))\n",
    "            elif column == 'Atlanta Retail':\n",
    "                atl.append(round(value,2))\n",
    "\n",
    "            elif column == 'Chicago Retail':\n",
    "                chi.append(round(value, 2))\n",
    "\n",
    "            elif column == 'Los Angeles Retail':\n",
    "                la.append(round(value, 2))\n",
    "\n",
    "            elif column == 'NYC Retail':\n",
    "                nyc.append(round(value,2))\n",
    "\n",
    "            count+=1\n",
    "            if count == 5:\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "    adj_2019_dict = {}\n",
    "\n",
    "    adj_2019_dict.setdefault('2019 Farm Price', farm)\n",
    "    adj_2019_dict.setdefault('2019 Atlanta retail', atl)\n",
    "    adj_2019_dict.setdefault('2019 Chicago Retail', chi)\n",
    "    adj_2019_dict.setdefault('2019 Los Angeles Retail',la)\n",
    "    adj_2019_dict.setdefault('2019 NYC Retail', nyc)\n",
    "    adj_2019_dict.setdefault('Avg Spread', list(df['Avg Spread']))\n",
    "    adj_2019_dict.setdefault('Commodity', list(df['Commodity']))\n",
    "    df_2019_adj = pd.DataFrame(adj_2019_dict)\n",
    "    df_2019_adj.index = df.index\n",
    "    \n",
    "    \n",
    "    avg_retail = [round(np.mean(x[1:5]),2) for x in df.values]\n",
    "    avg_retail_var = [round(np.var(x[1:5],ddof=1), 2) for x in df.values] \n",
    "    df_2019_adj['Avg_Retail'] = avg_retail\n",
    "    df_2019_adj['Avg_Retail_Var'] = avg_retail_var\n",
    "\n",
    "    \n",
    "    return df_2019_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for produce in list(produce_dict.keys()):\n",
    "    df = inflation_adjustment_for_df(produce_dict[produce])\n",
    "    df.to_pickle(f'../../data/02_processed/{produce}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Dataframes processed and ready for exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2019 Farm Price</th>\n",
       "      <th>2019 Atlanta retail</th>\n",
       "      <th>2019 Chicago Retail</th>\n",
       "      <th>2019 Los Angeles Retail</th>\n",
       "      <th>2019 NYC Retail</th>\n",
       "      <th>Avg Spread</th>\n",
       "      <th>Commodity</th>\n",
       "      <th>Avg_Retail</th>\n",
       "      <th>Avg_Retail_Var</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-05-19</th>\n",
       "      <td>1.17</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.55</td>\n",
       "      <td>82.33%</td>\n",
       "      <td>Nectarines</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-12</th>\n",
       "      <td>0.91</td>\n",
       "      <td>2.68</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.67</td>\n",
       "      <td>166.21%</td>\n",
       "      <td>Nectarines</td>\n",
       "      <td>2.42</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-05</th>\n",
       "      <td>0.58</td>\n",
       "      <td>2.43</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.92</td>\n",
       "      <td>302.59%</td>\n",
       "      <td>Nectarines</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-28</th>\n",
       "      <td>0.58</td>\n",
       "      <td>2.81</td>\n",
       "      <td>1.96</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.98</td>\n",
       "      <td>334.48%</td>\n",
       "      <td>Nectarines</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-21</th>\n",
       "      <td>0.69</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2.05</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.18</td>\n",
       "      <td>280.43%</td>\n",
       "      <td>Nectarines</td>\n",
       "      <td>2.62</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-07-01</th>\n",
       "      <td>1.41</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.62</td>\n",
       "      <td>2.96</td>\n",
       "      <td>3.80</td>\n",
       "      <td>424.17%</td>\n",
       "      <td>Nectarines</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-06-24</th>\n",
       "      <td>1.44</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.42</td>\n",
       "      <td>3.02</td>\n",
       "      <td>3.61</td>\n",
       "      <td>293.02%</td>\n",
       "      <td>Nectarines</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-06-17</th>\n",
       "      <td>1.23</td>\n",
       "      <td>3.96</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.86</td>\n",
       "      <td>209.26%</td>\n",
       "      <td>Nectarines</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-06-10</th>\n",
       "      <td>1.21</td>\n",
       "      <td>4.32</td>\n",
       "      <td>3.55</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.68</td>\n",
       "      <td>232.33%</td>\n",
       "      <td>Nectarines</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-06-03</th>\n",
       "      <td>1.46</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.14</td>\n",
       "      <td>3.60</td>\n",
       "      <td>202.82%</td>\n",
       "      <td>Nectarines</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13821 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            2019 Farm Price  2019 Atlanta retail  2019 Chicago Retail  \\\n",
       "Date                                                                    \n",
       "2019-05-19             1.17                 2.24                 1.71   \n",
       "2019-05-12             0.91                 2.68                 1.90   \n",
       "2019-05-05             0.58                 2.43                 1.90   \n",
       "2019-04-28             0.58                 2.81                 1.96   \n",
       "2019-04-21             0.69                 2.94                 2.05   \n",
       "...                     ...                  ...                  ...   \n",
       "2001-07-01             1.41                 3.98                 3.62   \n",
       "2001-06-24             1.44                 3.60                 3.42   \n",
       "2001-06-17             1.23                 3.96                 2.25   \n",
       "2001-06-10             1.21                 4.32                 3.55   \n",
       "2001-06-03             1.46                 3.25                 3.25   \n",
       "\n",
       "            2019 Los Angeles Retail  2019 NYC Retail Avg Spread   Commodity  \\\n",
       "Date                                                                          \n",
       "2019-05-19                     2.00             2.55     82.33%  Nectarines   \n",
       "2019-05-12                     2.48             2.67    166.21%  Nectarines   \n",
       "2019-05-05                     2.13             2.92    302.59%  Nectarines   \n",
       "2019-04-28                     2.40             2.98    334.48%  Nectarines   \n",
       "2019-04-21                     2.40             3.18    280.43%  Nectarines   \n",
       "...                             ...              ...        ...         ...   \n",
       "2001-07-01                     2.96             3.80    424.17%  Nectarines   \n",
       "2001-06-24                     3.02             3.61    293.02%  Nectarines   \n",
       "2001-06-17                     3.06             3.86    209.26%  Nectarines   \n",
       "2001-06-10                     2.88             3.68    232.33%  Nectarines   \n",
       "2001-06-03                     3.14             3.60    202.82%  Nectarines   \n",
       "\n",
       "            Avg_Retail  Avg_Retail_Var  \n",
       "Date                                    \n",
       "2019-05-19        2.12            0.13  \n",
       "2019-05-12        2.42            0.13  \n",
       "2019-05-05        2.33            0.19  \n",
       "2019-04-28        2.52            0.20  \n",
       "2019-04-21        2.62            0.26  \n",
       "...                ...             ...  \n",
       "2001-07-01        1.57            0.08  \n",
       "2001-06-24        1.69            0.01  \n",
       "2001-06-17        1.67            0.14  \n",
       "2001-06-10        1.93            0.03  \n",
       "2001-06-03        1.88            0.12  \n",
       "\n",
       "[13821 rows x 9 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agriculture-project",
   "language": "python",
   "name": "agriculture-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
